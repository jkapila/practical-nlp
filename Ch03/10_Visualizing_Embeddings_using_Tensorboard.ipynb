{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will demonstrate how you can use Tensorboard to visualize word embeddings which we created in the Training_embeddings_using_gensim.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2 MB 4.3 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.28.1-cp36-cp36m-manylinux2010_x86_64.whl (2.8 MB)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Using cached protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Processing /home/etherealenvy/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.1-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 125 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.6/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Processing /home/etherealenvy/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679/absl_py-0.9.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.6/site-packages (from tensorflow==1.14.0) (1.18.4)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.6/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Processing /home/etherealenvy/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63/wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting h5py\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: setuptools in /home/etherealenvy/.local/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/etherealenvy/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 711 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
      "Installing collected packages: google-pasta, grpcio, h5py, keras-applications, astor, protobuf, tensorflow-estimator, gast, termcolor, keras-preprocessing, absl-py, markdown, tensorboard, wrapt, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.3.3 google-pasta-0.2.0 grpcio-1.28.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.1 markdown-3.2.2 protobuf-3.11.3 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "#installing the required libraries\n",
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the required imports\n",
    "import warnings #ignoring the generated warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "filename = \"File-Path\"\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the model's vocabulary size\n",
    "max_size = len(model.wv.vocab)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a numpy array of 0s with the size of the vocabulary and dimensions of our model\n",
    "w2v = np.zeros((max_size,model.wv.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create a new file called metadata.tsv where we save all the words in our model \n",
    "#we also store the embedding of each word in the w2v matrix\n",
    "if not os.path.exists('projections'):\n",
    "    os.makedirs('projections')\n",
    "    \n",
    "with open(\"projections/metadata.tsv\", 'w+') as file_metadata:\n",
    "    \n",
    "    for i, word in enumerate(model.wv.index2word[:max_size]):\n",
    "        \n",
    "        #store the embeddings of the word\n",
    "        w2v[i] = model.wv[word]\n",
    "        \n",
    "        #write the word to a file \n",
    "        file_metadata.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing tf session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the tensorflow variable called embeddings that holds the word embeddings:\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.Variable(w2v, trainable=False, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize all variables\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object of the saver class which is actually used for saving and restoring variables to and from our checkpoints\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with FileWriter,we save summary and events to the event file\n",
    "writer = tf.summary.FileWriter('projections', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the projectors and add the embeddings\n",
    "config = projector.ProjectorConfig()\n",
    "embed= config.embeddings.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify our tensor_name as embedding and metadata_path to the metadata.tsv file\n",
    "embed.tensor_name = 'embedding'\n",
    "embed.metadata_path = 'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projections/model.ckpt-161017'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "saver.save(sess, 'projections/model.ckpt', global_step=max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal window and type the following command\n",
    "\n",
    "tensorboard --logdir=projections --port=8000\n",
    "\n",
    "If the tensorboard does not work for you try providing the absolute path for projections and re-run the above command\n",
    "\n",
    "If youve done everything right until you will get a link in your terminal through which you can access the tensorboard. Click on the link or copy paste it in your browser. You should see something similar to this.\n",
    "![TensorBoard-1](Images/TensorBoard-1.png)\n",
    "<br>\n",
    "In the top right corner near \"INACTIVE\" click the dropdown arrow. And select PROJECTIONS from te dropdown menu\n",
    "![TensorBoard-2](Images/TensorBoard-2.png)\n",
    "<br>\n",
    "Wait for a few seconds for it to load. You can now see your embeddings there are a lot of setting you can play around and experiment with.\n",
    "![TensorBoard-3](Images/TensorBoard-3.png)\n",
    "<br>\n",
    "Output when we search for a specific word in this case \"human\" and isolate only those points\n",
    "![TensorBoard-4](Images/TensorBoard-4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
